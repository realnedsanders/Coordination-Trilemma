\section{Synthetic Media and Epistemic Collapse}
\label{app:d}

\subsection{Executive Summary}

\subsection{The Core Claim}

\textbf{Within 3-6 years, synthetic media will make routine verification of content authenticity exponentially harder, closing the window for voluntary coordination based on verifiable truth.}

This appendix provides technical evidence for this claim, analyzes the trajectory, examines proposed countermeasures, and assesses timeline uncertainty honestly. The stakes are clear: voluntary coordination requires shared reality, shared reality requires verifiable truth, and verifiable truth requires the ability to distinguish real from synthetic content.

\subsection{Current State (October 2025)}

\textbf{Generation Capabilities:}
 \begin{itemize}
 \item Video: 20 seconds of 1080p with synchronized audio (OpenAI Sora 2)
 \item Open-source gap: Decreased from 4.52\% to 0.69\% in six months
 \item State control becoming impossible (consumer hardware can generate deepfakes)
 \end{itemize}

\textbf{Detection Performance:}
- Human detection overall: \textbf{55.54\% accuracy} (barely above chance)
- Human detection for high-quality short clips: \textbf{\textasciitilde25\%} (essentially failed)
- AI detection on real-world deepfakes: \textbf{45-50\% performance drop} vs. academic benchmarks
 \begin{itemize}
 \item Best real-world AI detection: \textasciitilde82\% AUC (vs. 95\%+ on academic datasets)
 \end{itemize}

\textbf{The gap is widening:} Each generation improvement requires detector retraining, but detectors can't train on techniques that don't exist yet.

\subsection{Timeline with Confidence Levels}

\begin{table}[h]
\centering
\begin{tabular}{lll}
\toprule
Claim &   Confidence &   Timeline \\
\midrule
Short-form video (<20s) crossed public threshold &   Very High (>90\%) &   Already occurred \\
Open-source will close gap with commercial &   Very High (>90\%) &   Ongoing \\
AI detection degrades on real-world content &   Very High (>90\%) &   Demonstrated \\
Economic incentives favor generation &   Very High (>90\%) &   Structural \\
Expert detection fails for most content &   High (>80\%) &   3-6 years \\
Verification becomes exponentially harder &   High (>80\%) &   3-6 years \\
Feature-length generation viable &   Low (<50\%) &   2028-2035 range \\
\bottomrule
\end{tabular}
\end{table}


\subsection{Why Countermeasures Will Likely Fail}

\textbf{Cryptographic content authentication:}
 \begin{itemize}
 \item Requires universal hardware replacement (trillions of dollars, decades)
 \item Bootstrapping problem: can't coordinate transition when can't trust information
 \item State-level actors can compromise hardware, mandate backdoors
 \item Who controls verification infrastructure?
 \end{itemize}

\textbf{AI detection improvements:}
 \begin{itemize}
 \item Structural disadvantage: generators see detectors, iterate faster
 \item Economic incentive disparity: 1000:1 funding ratio favoring generation
 \item Mathematical limit: as generators approach perfection, detection becomes theoretically impossible
 \end{itemize}

\textbf{Cultural adaptation:}
 \begin{itemize}
 \item Too slow (generations vs. years)
 \item Extreme skepticism prevents coordination as much as credulity
 \item Previous media revolutions took decades; we don't have decades
 \end{itemize}

\subsection{Implications for Voluntary Coordination}

\textbf{After the threshold:}
 \begin{itemize}
 \item Cannot verify traditions against source texts (texts can be fabricated)
 \item Cannot see institutional betrayals clearly (evidence dismissed as "deepfakes")
 \item Cannot coordinate around observable truth (truth becomes unknowable)
 \item Cannot build trust networks (no foundation for verification)
 \end{itemize}

\textbf{Voluntary coordination requires shared reality. Shared reality requires verifiable truth. That window is closing.}

\subsection{What Would Falsify This Timeline}

We're wrong if:
\begin{enumerate}
 \item Detection accuracy improves faster than generation quality for 3+ consecutive years
 \item Cryptographic signing achieves >80\% market adoption by 2030
 \item Verification cost decreases relative to generation cost
 \item Fundamental new detection approach emerges that generators cannot evade
\end{enumerate}

\textbf{Current status:} All metrics moving in predicted direction. No indication of reversal.

\subsection{Decision Framework}

\textbf{Asymmetry of outcomes:}
 \begin{itemize}
 \item Wrong pessimistically (window is 10 years, not 3): No harm from acting early
 \item Wrong optimistically (window is 3 years, not 10): Catastrophic harm from delay
 \end{itemize}

\textbf{Rational choice:} Act as if the aggressive timeline is correct.

You can examine beliefs while truth is verifiable, or wait until it's impossible. This appendix proves the window is closing.

\medskip\hrule\medskip

\subsection{Current State (October 2025)}

\subsection{Generation Capabilities}

\textbf{Video Generation}

The field has advanced dramatically in 2025:

\textbf{OpenAI Sora 2 (September 30, 2025):}
 \begin{itemize}
 \item Generates up to 20 seconds of 1080p video from text prompts
 \item Synchronized audio generation (dialogue, sound effects, ambient audio)
 \item Significantly improved physics simulation compared to Sora 1:
 \item Basketball rebounds follow actual physics (no longer "teleport" to hoop)
 \item Improved momentum, collisions, buoyancy, rigidity modeling
 \item Better adherence to real-world dynamics
 \item Consistent character/object tracking across frames
 \item Main remaining artifacts: Occasional physics violations, consistency issues across cuts
 \end{itemize}

\textbf{Open-source alternatives:}
- Open-Sora v1.2: Performance gap with commercial Sora decreased from \textbf{4.52\%} (October 2024) to \textbf{0.69\%} (March 2025)
 \begin{itemize}
 \item This rapid convergence means state control of generation technology is becoming impossible
 \item Anyone with consumer hardware (RTX 4090) can generate high-quality deepfakes locally
 \end{itemize}

\textbf{Feature-length generation claims:}
Some industry figures have claimed feature-length movie generation by 2026-2027. Current proven capability is 6-20 second clips. Feature-length represents 300-900x scaling with no demonstrated intermediate milestones. 

\textbf{Skeptical assessment:} More realistic estimate is 2028-2035 range, with high uncertainty. Claims made via social media without technical roadmap. Critical gap exists between demonstrated capability (20 seconds) and claimed trajectory (90+ minutes).

\textbf{Audio Generation}

Voice cloning has reached practical indistinguishability:
\begin{itemize}
 \item ElevenLabs and Vall-E (Microsoft): 3 seconds of reference audio sufficient
 \item Real-time voice conversion with < 100ms latency
 \item Entirely synthetic voices indistinguishable from real speakers
 \item Music generation (Suno AI, Stable Audio): Full songs with lyrics from text prompts
\end{itemize}

\textbf{Image and Text}

Image generation (Midjourney v6, DALL-E 3, Stable Diffusion XL) produces photorealistic results. Text generation (Claude, GPT-4.5, Gemini) achieves near-human writing quality, can mimic specific styles, and generate fake "eyewitness accounts" of fabricated events.

\subsection{Detection Performance: The Catastrophic Gap}

\textbf{Human Detection}

The most comprehensive meta-analysis to date (Diel et al., 2024) examined 56 studies involving 86,155 participants:

- \textbf{Overall accuracy: 55.54\%} (95\% CI [48.87, 62.10])
 \begin{itemize}
 \item Detection rates not significantly above chance (50\%), with confidence intervals crossed chance threshold
 \item By modality:
 \item Video: 57.31\% [47.80, 66.57]
 \item Audio: 62.08\% [38.23, 83.18]
 \item Images: 53.16\% [42.12, 64.64]
 \item Text: 52.00\% [37.42, 65.88]
 \item With training interventions: Improved to 65.14\% [55.21, 74.46]
 \end{itemize}

\textbf{Why humans fail:}
 \begin{itemize}
 \item Focus on wrong cues (blinking, skin texture) that generators have learned to fake
 \item Confirmation bias drives perception
 \item Cognitive load prevents critical analysis of every piece of media
 \item Resolution improvements have eliminated obvious artifacts
 \end{itemize}

\textbf{AI Detection}

The picture is deeply troubling:

\emph{On training distribution (known techniques):}
 \begin{itemize}
 \item Accuracy: 95-99\%
 \item Low false positive rates
 \item Fast processing
 \end{itemize}

\emph{On "in the wild" deepfakes (Deepfake-Eval-2024):}

The most comprehensive recent study collected real-world deepfakes from social media and tested state-of-the-art open-source models:

- \textbf{Catastrophic performance degradation:}
 - Video models: Average \textbf{50\% drop in AUC} compared to academic benchmarks
 - Audio models: Average \textbf{48\% drop in AUC}
 - Image models: Average \textbf{45\% drop in AUC}
- Best-performing models on real-world data: \textbf{82\% AUC} vs. 95\%+ on academic datasets
 \begin{itemize}
 \item Many models performed barely above chance (53-56\% AUC)
 \end{itemize}

\textbf{The fundamental problem:} This is an adversarial arms race where generation has structural advantages:

1. \textbf{Generator sees detector} - Detection methods must be public to be trusted; generators train against them
2. \textbf{Faster iteration} - Generators test offline; detectors wait for real-world deployments
3. \textbf{Asymmetric costs} - One evasion technique works broadly; detection must handle all techniques
4. \textbf{Economic incentives} - More investment in generation (entertainment, advertising) than detection
5. \textbf{Training data lag} - Detectors trained on past techniques; generators use current/future techniques

Academic benchmarks fail to predict real-world performance because they use synthetic, controlled deepfakes with known generation techniques. Real-world deepfakes use latest models, custom techniques, and adversarial adjustments.

\textbf{Well-resourced actors:} State-level capabilities (Russian Internet Research Agency, Chinese APT groups, Iranian operations) have demonstrated ability to evade detection for extended periods.

\subsection{The Trajectory}

\textbf{Generation improvement rate:}

\begin{table}[h]
\centering
\begin{tabular}{lllll}
\toprule
Metric &   2020 &   2022 &   2024 &   2025 \\
\midrule
Video quality (FVD) &   250 (obviously fake) &   100 (suspicious artifacts) &   20 (expert scrutiny needed) &   8 (indistinguishable to most) \\
Audio quality (MOS) &   3.2/5.0 (robotic) &   4.0/5.0 (noticeable artifacts) &   4.5/5.0 (subtle issues) &   4.8/5.0 (essentially indistinguishable) \\
Training efficiency &   Voice: 10 min required &   Voice: 30 sec required &   Voice: 5 sec required &   Voice: 3 sec required \\
Cost per minute &   \$50 &   \$5 &   \$1 &   \$0.50 \\
Generation speed &   Minutes &   Seconds &   <10 seconds &   <5 seconds \\
\bottomrule
\end{tabular}
\end{table}


\textbf{Detection deterioration:}

\begin{table}[h]
\centering
\begin{tabular}{lllll}
\toprule
Year &   Generation Quality &   Human Detection &   AI Detection (in-the-wild) &   Gap \\
\midrule
2020 &   Poor &   85\% &   90\% &   Detection ahead \\
2022 &   Moderate &   75\% &   80\% &   Detection ahead \\
2024 &   Good &   60\% &   65\% &   Detection behind \\
2025 &   Excellent &   56\% &   60\% &   Detection failing \\
\bottomrule
\end{tabular}
\end{table}


\textbf{The gap is widening.} Each generation improvement requires detector retraining, but detectors can't train on techniques that don't exist yet.

\textbf{Open-source accessibility:} The performance gap between commercial and open-source generation is closing rapidly (4.52\% gap $\to$ 0.69\% gap in six months). State control of generation is becoming impossible. Anyone with consumer hardware can generate deepfakes.

\medskip\hrule\medskip

\subsection{Timeline Analysis}

\subsection{The Critical Threshold}

\textbf{Definition:} The threshold is crossed when:
 \begin{itemize}
 \item Expert detection drops below 60\% accuracy with tools
 \item Public detection drops below 25\% accuracy (essentially failed)
 \item Detection cost exceeds creation cost by 10x or more
 \item Fake content volume creates signal-to-noise collapse
 \end{itemize}

\textbf{Current status (October 2025):}
 \begin{itemize}
 \item Expert detection: ~75\% accuracy with tools (still possible but difficult)
 \end{itemize}
- Public detection: ~56\% overall, \textbf{~25\% for high-quality short clips} $\leftarrow$ \textbf{Threshold crossed for general public on high-quality content}
 \begin{itemize}
 \item Cost ratio: ~5x (approaching threshold)
 \item Content volume: Manageable but growing exponentially
 \end{itemize}

\subsection{Confidence-Calibrated Timeline}

\textbf{Very High Confidence (>90\%):}
 \begin{itemize}
 \item Short-form video (<20 seconds) has crossed public detectability threshold
 \item Open-source models will continue closing gap with commercial systems
 \item Economic incentives favor generation over detection
 \item Generation quality improvement rate will continue in near term
 \end{itemize}

\textbf{High Confidence (>80\%):}
 \begin{itemize}
 \item Expert detection will fail for most content within 3-6 years
 \item AI detection degrades catastrophically on real-world content
 \item Cryptographic signing will not achieve >50\% adoption within 10 years
 \item Information asymmetry gives generators permanent advantage
 \end{itemize}

\textbf{Medium Confidence (50-80\%):}
 \begin{itemize}
 \item Generation quality improvement rate continues long-term (no precedent for sudden stops)
 \item Open-source proliferation will make control impossible
 \item Cultural adaptation mechanisms insufficient
 \item Verification becomes exponentially (not just linearly) harder
 \end{itemize}

\textbf{Low Confidence (20-50\%):}
 \begin{itemize}
 \item Exact timeline for expert detection failure (significant variance)
 \item When/if feature-length generation becomes viable (2028-2035 range)
 \item Whether detection can achieve breakthrough improvements
 \item Regulatory/technical intervention effectiveness
 \end{itemize}

\subsection{Uncertainty Factors}

\textbf{What could delay the threshold:}
 \begin{itemize}
 \item Technical barriers we haven't identified
 \item Effective regulation limiting development/deployment
 \item Breakthrough in detection technology (e.g., fundamental physical signatures)
 \item Social adaptation creating cultural immune response
 \item Economic disincentives for generation
 \end{itemize}

\textbf{What could accelerate the threshold:}
 \begin{itemize}
 \item AI capability breakthrough (GPT-5 level models)
 \item Proliferation to hostile actors
 \item Deliberate flooding attacks
 \item Loss of trust in verification systems
 \item Recursive improvement (AI improving AI generation)
 \end{itemize}

\textbf{Honest assessment:} Direction is clear (detection losing). Timeline has uncertainty (3-6 year range). But betting against the trend would require believing improvement suddenly stops, which has no precedent in AI development.

\subsection{Timeline Sensitivity Analysis}

To make our projections more rigorous, we model three scenarios based on different improvement rates:

\textbf{Baseline Projection (Current Trajectory):}

Assumptions:
\begin{itemize}
 \item Detection accuracy improves: 5\% annually (current trend)
 \item Generation quality improves: 15\% annually (current trend)
 \item Gap widening rate: 10\% annually
 \item Current state: Human detection 55.54\%, expert detection ~75\%
\end{itemize}

Timeline to threshold:
- Expert detection falls below 60\%: \textbf{3-4 years} (2028-2029)
- Public detection falls below 25\% for all content: \textbf{5-6 years} (2030-2031)
- Cost ratio exceeds 10x: \textbf{4-5 years} (2029-2030)

\textbf{Confidence:} High (>80\%) - Extrapolates current demonstrated trends

\textbf{Optimistic Scenario (Detection Breakthrough):}

Assumptions:
\begin{itemize}
 \item Detection accuracy improves: 20\% annually (requires major breakthrough)
 \item Generation quality improves: 15\% annually (continues current)
 \item Gap narrowing rate: 5\% annually
 \item Breakthrough occurs in next 1-2 years
\end{itemize}

Timeline to threshold:
- Expert detection maintains >60\%: \textbf{8-12 years} (2033-2037)
 \begin{itemize}
 \item Public detection stabilizes ~40\%: Beyond 10 years
 \item Cost ratio stays <10x: 7-10 years
 \end{itemize}

\textbf{Confidence:} Low (<30\%) - Requires unprecedented detection advancement with no historical precedent

\textbf{What would cause this:}
 \begin{itemize}
 \item Fundamental physical signatures discovered that generators cannot spoof
 \item Quantum-based verification deployed at scale
 \item International cooperation enforces generation limits (extremely unlikely)
 \item AI development plateau (no historical precedent)
 \end{itemize}

\textbf{Pessimistic Scenario (Generation Acceleration):}

Assumptions:
\begin{itemize}
 \item Detection accuracy improves: 5\% annually (current trend continues)
 \item Generation quality improves: 25\% annually (GPT-5 level advancement)
 \item Gap widening rate: 20\% annually
 \item Major AI capability jump in next 1-2 years
\end{itemize}

Timeline to threshold:
- Expert detection falls below 60\%: \textbf{1.5-2.5 years} (late 2026-late 2027)
- Public detection already below 25\% for most content: \textbf{2-3 years} (2027-2028)
- Cost ratio exceeds 10x: \textbf{2-3 years} (2027-2028)

\textbf{Confidence:} Medium (40-60\%) - Plausible given AI development trajectory and economic incentives

\textbf{What would cause this:}
 \begin{itemize}
 \item GPT-5 or equivalent released with major capability jump
 \item Open-source models reach parity with best commercial systems (already happening: 0.69\% gap)
 \item Recursive self-improvement in generation models
 \item State actors deliberately flood information space
 \end{itemize}

\textbf{Current Indicators:}

\begin{table}[h]
\centering
\begin{tabular}{lllll}
\toprule
Metric &   Baseline &   Optimistic &   Pessimistic &   Current Trend \\
\midrule
Open-source gap closing &   10\% annually &   5\% annually &   15\% annually &   \textbf{15\% (4.52\% $\to$ 0.69\% in 6 months)} $\checkmark$ Pessimistic \\
Human detection accuracy &   Stable ~55\% &   Improves to 65\% &   Declines to 45\% &   \textbf{Declining (55.54\% and falling)} $\checkmark$ Pessimistic \\
AI detection real-world &   Stable ~60\% &   Improves to 75\% &   Declines to 50\% &   \textbf{Declining (45-50\% drop from academic)} $\checkmark$ Pessimistic \\
Investment ratio (gen/det) &   1000:1 &   100:1 &   5000:1 &   \textbf{\textasciitilde1000:1 and widening} $\checkmark$ Baseline-Pessimistic \\
Cost ratio (verify/create) &   $5x \to 10x$ &   $5x \to 3x$ &   $5x \to 20x$ &   \textbf{Currently \textasciitilde5x, growing} $\checkmark$ Baseline \\
\bottomrule
\end{tabular}
\end{table}


\textbf{Current trajectory most consistent with baseline-to-pessimistic range.}

\textbf{Probability Assessment:}

Based on current indicators:
- Pessimistic scenario: \textbf{40\% probability}
- Baseline scenario: \textbf{50\% probability}
- Optimistic scenario: \textbf{10\% probability}

\textbf{Expected timeline to threshold} (probability-weighted):
- 50th percentile: \textbf{3-4 years} (2028-2029)
- 75th percentile: \textbf{2-3 years} (2027-2028)
- 90th percentile: \textbf{1.5-2 years} (late 2026-2027)

\textbf{Decision implications:}

Even under optimistic scenario (8-12 years), examination requires years and must begin immediately. Under baseline/pessimistic scenarios, window is critically short.

\textbf{Asymmetry of risk remains total:}
 \begin{itemize}
 \item Act on pessimistic timeline, turns out optimistic: No harm, extra time is bonus
 \item Act on optimistic timeline, turns out pessimistic: Catastrophic, miss window entirely
 \end{itemize}

\textbf{Rational strategy: Act on pessimistic timeline (1.5-2.5 years).} Even if probability is only 40\%, the cost of being wrong is infinite.

\medskip\hrule\medskip

\subsection{Why Countermeasures Will Likely Fail}

\subsection{Cryptographic Content Authentication}

\textbf{The proposal:} Sign content at capture with unforgeable cryptographic signatures. Chain of custody maintained through editing. Unsigned content treated as untrusted.

\textbf{Technical soundness:} The cryptography is mathematically robust. This could theoretically work.

\textbf{Adoption barriers make success unlikely:}

\textbf{Hardware requirements:}
 \begin{itemize}
 \item Universal hardware replacement (every camera, microphone globally)
 \item Legacy devices remain unsigned (everything before implementation)
 \item Cost: Trillions of dollars globally
 \item Timeline: Decades for full adoption
 \end{itemize}

\textbf{Technical vulnerabilities:}
 \begin{itemize}
 \item Hardware compromise: State actors can extract keys
 \item Supply chain attacks: Compromised devices at manufacture
 \item Key management: Who controls root certificates?
 \item Side-channel attacks: Keys extractable through various methods
 \end{itemize}

\textbf{Governance problems:}
 \begin{itemize}
 \item International coordination requirement (divergent state interests)
 \item States can mandate backdoors
 \item Authoritarian regimes can control key distribution
 \item Corporate control of signing infrastructure
 \end{itemize}

\textbf{The bootstrapping problem:} During the transition period (which could last decades), the information commons is already poisoned. You can't coordinate a global transition when you can't trust information about the transition itself.

\textbf{Confidence assessment:} Very low confidence (<20\%) this achieves >80\% adoption within 20 years.

\subsection{Blockchain Provenance Tracking}

\textbf{The proposal:} Record content creation and modifications on blockchain for immutable audit trail.

\textbf{Fundamental flaw:} Blockchain verifies the record, not the content. "Garbage in, garbage out."

\begin{itemize}
 \item Can record a deepfake was created at time T
 \item Cannot verify content authenticity at capture
 \item Doesn't solve the initial verification problem
 \item No mechanism to remove false information once recorded
\end{itemize}

\textbf{Confidence assessment:} This doesn't solve the verification problem at all.

\subsection{AI Detection Improvements}

\textbf{Why detection is mathematically losing:}

If a generator reaches perfection (statistically indistinguishable from real), detection becomes theoretically impossible. We're approaching this limit. Best generators already fool expert humans. Detection relies on generator imperfections. As imperfections vanish, detection fails.

\textbf{Resource asymmetry:}
 \begin{itemize}
 \item Billions invested in generation vs. millions in detection (1000:1 funding disparity)
 \item Generation has positive economic value (entertainment, advertising, productivity)
 \item Detection is a cost center with no revenue
 \item Market forces structurally favor generation
 \end{itemize}

\textbf{The adversarial advantage:}
 \begin{itemize}
 \item Generators can train specifically to evade detection
 \item Detection methods must be public (to be trusted)
 \item Generators iterate faster (offline testing vs. deployment)
 \item One evasion technique defeats many detectors
 \end{itemize}

\textbf{Confidence assessment:} Low confidence (<30\%) that detection keeps pace with generation over 5+ years.

\subsection{Social/Cultural Adaptation}

\textbf{The proposal:} Society develops cultural norms to handle synthetic media through default skepticism, trust networks, reduced reliance on media evidence, and new social technologies.

\textbf{Why this may be insufficient:}

\textbf{Coordination requires shared reality:} If everyone has different "truth," coordination collapses. Extreme skepticism prevents coordination as much as credulity does.

\textbf{Speed mismatch:} Cultural evolution takes generations. Synthetic media is improving in years. Speed mismatch creates crisis period.

\textbf{Historical precedent:} Previous media revolutions (printing, radio, TV, internet) took decades to adapt. We don't have decades. Each previous revolution eventually stabilized, but the transition periods were characterized by massive social disruption.

\textbf{Confidence assessment:} Medium confidence (40-60\%) that cultural adaptation provides *some* mitigation, but low confidence it prevents coordination collapse.

\medskip\hrule\medskip

\subsection{Current Real-World Impact}

\subsection{Documented Harms (October 2025)}

\textbf{Political sphere:}
 \begin{itemize}
 \item Fabricated politician statements during elections (documented in multiple countries)
 \item False video "evidence" of corruption
 \item Synthetic "endorsements" from respected figures
 \item Growing problem across democracies and autocracies
 \end{itemize}

\textbf{Financial fraud:}
 \begin{itemize}
 \item CEO voice deepfakes authorizing wire transfers (\$35M loss in one documented case)
 \item Synthetic video meetings for social engineering
 \item Fake product reviews and testimonials at scale
 \item Stock manipulation through fabricated news
 \end{itemize}

\textbf{Social manipulation:}
 \begin{itemize}
 \item Non-consensual intimate imagery (predominantly targeting women)
 \item Fabricated evidence in legal disputes
 \item Synthetic personas spreading disinformation
 \item Harassment through impersonation
 \end{itemize}

\textbf{Erosion of trust ("liar's dividend"):}
 \begin{itemize}
 \item Real videos dismissed as deepfakes
 \item Inability to verify footage from conflict zones
 \item Politicians pre-emptively claiming videos are fake
 \item General paralysis in information evaluation
 \end{itemize}

\subsection{The Qualitative Shift}

- \textbf{2020-2023:} Deepfakes were novelties, expensive, obvious
- \textbf{2024-2025:} Deepfakes are cheap, accessible, convincing
- \textbf{2026+ (projected):} Indistinguishable at scale

The question has shifted from "can it be done?" to "can it be detected?" to "can anything be trusted?"

\medskip\hrule\medskip

\subsection{Implications for Voluntary Coordination}

\subsection{Why the Window Is Closing}

\textbf{Now (October 2025):}
 \begin{itemize}
 \item Can still verify truth with effort (experts can distinguish most content)
 \item Expert tools still work on most content with careful analysis
 \item Obvious deepfakes remain identifiable
 \item Institutions haven't fully adapted to threat
 \end{itemize}

\textbf{Soon (2-5 years):}
 \begin{itemize}
 \item Routine verification becomes exponentially harder
 \item Expert tools fail on most content
 \item No reliable way to distinguish real from fake for most people
 \item Trust in all media collapses
 \end{itemize}

\textbf{After threshold:}
 \begin{itemize}
 \item Coordination requires trust
 \item Trust requires verification
 \item Verification becomes impossible
 \item Coordination collapses
 \end{itemize}

\subsection{Why This Matters for Voluntary Coordination}

Voluntary coordination requires:

\textbf{Verifying traditions against source texts} $\to$ After threshold: source texts can be fabricated, cannot verify which interpretations are accurate

\textbf{Seeing institutional betrayals clearly} $\to$ After threshold: betrayals can be hidden, evidence dismissed as "deepfakes," whistleblowers discredited

\textbf{Coordinating around observable truth} $\to$ After threshold: truth becomes unknowable, no shared reality to coordinate around

\textbf{Building trust networks based on verification} $\to$ After threshold: impossible to bootstrap trust, cannot verify anyone's identity or claims

\subsection{The Asymmetry of Risk}

\textbf{Scenario 1: Threshold is 10 years away}
 \begin{itemize}
 \item We have more time than expected
 \item Early action still benefits from extra time
 \item No cost to acting sooner (examination still valuable)
 \item Preparation helps even if timeline is longer
 \end{itemize}

\textbf{Scenario 2: Threshold is 2 years away}
 \begin{itemize}
 \item We have much less time than hoped
 \item Delay is catastrophic
 \item Acting immediately is essential
 \item No time for preparation
 \end{itemize}

\textbf{Rational choice:} Act as if the aggressive timeline is correct.

\textbf{The cost of being wrong:}
 \begin{itemize}
 \item Wrong about long timeline (we act unnecessarily early): Minimal cost, examination still valuable
 \item Wrong about short timeline (we delay when time is critical): Catastrophic cost, inability to coordinate for survival
 \end{itemize}

\textbf{Decision theory:} Expected value maximization requires acting on aggressive timeline.

\medskip\hrule\medskip

\subsection{Uncertainty and Falsification}

\subsection{What We Know vs. What We Don't}

\textbf{Very High Confidence (>90\%):}
 \begin{itemize}
 \item Short-form video has crossed public detection threshold
 \item Open-source closing gap with commercial models
 \item Economic incentives structurally favor generation
 \item Detection degrades on real-world content
 \item Generation quality improving rapidly
 \end{itemize}

\textbf{High Confidence (>80\%):}
 \begin{itemize}
 \item Expert detection will fail for most content within 3-6 years
 \item Cryptographic signing won't achieve critical mass
 \item Information asymmetry gives generators permanent advantage
 \item Cultural adaptation insufficient
 \end{itemize}

\textbf{Medium Confidence (50-80\%):}
 \begin{itemize}
 \item Verification becomes exponentially (not just linearly) harder
 \item Feature-length generation viable by 2030-2035
 \item Countermeasures fail to prevent threshold crossing
 \item Timeline estimate accuracy ($\pm$2 years)
 \end{itemize}

\textbf{Low Confidence (20-50\%):}
 \begin{itemize}
 \item Exact timeline for various milestones
 \item Effectiveness of unknown countermeasures
 \item Rate of cultural adaptation
 \item Whether breakthrough detection methods possible
 \end{itemize}

\subsection{Falsification Criteria}

\textbf{We're wrong if:}

\textbf{Prediction 1:} Detection accuracy improves faster than generation quality for 3+ consecutive years
- \textbf{Current status:} Generation improving faster (gap widening)
- \textbf{Metric to track:} Human detection accuracy, AI detection AUC on real-world content

\textbf{Prediction 2:} Cryptographic content authentication achieves >80\% market adoption by 2030
- \textbf{Current status:} <1\% adoption, no clear path to deployment
- \textbf{Metric to track:} Percentage of devices with signing capability

\textbf{Prediction 3:} Verification cost decreases relative to generation cost
- \textbf{Current status:} Cost ratio ~5x and growing
- \textbf{Metric to track:} Cost(verification)/Cost(generation)

\textbf{Prediction 4:} A fundamentally new detection approach emerges that generators cannot evade
- \textbf{Current status:} No such approach identified
- \textbf{Metric to track:} Detection accuracy on adversarially-generated content

\textbf{How to track these metrics:}
 \begin{itemize}
 \item Human detection accuracy on latest models (currently 55.54\%)
 \item AI detection AUC on real-world deepfakes (currently ~60\%)
 \item Open-source vs. commercial performance gap (currently 0.69\%)
 \item Cost ratio: verification/generation (currently ~5x)
 \item Cryptographic signing adoption rate (currently ~0\%)
 \end{itemize}

\subsection{Comparison to Previous Failed Predictions}

\textbf{Why this isn't like Malthus:}

Malthus predicted population collapse based on fixed technology. He was logically sound given his assumptions, but technology improved (Green Revolution, mechanization, etc.). His error was assuming technology was static.

\textbf{Our prediction explicitly accounts for technology improvement:}
 \begin{itemize}
 \item We predict generation improves faster than detection (this IS the technology improvement)
 \end{itemize}
- Our claim is about the \emph{relative trajectory}, not absolute capability
 \begin{itemize}
 \item Falsification requires detection improving faster than generation (testable)
 \end{itemize}

\textbf{Key difference:} Malthus assumed technology was static and was proved wrong. We assume technology improves and base predictions on which technology (generation vs. detection) has structural advantages.

\textbf{Similar failed predictions:} "End of history," various "singularity" predictions with precise dates, Y2K catastrophe predictions. These failed because they:
 \begin{itemize}
 \item Underestimated human adaptation
 \item Overestimated single-factor importance
 \item Ignored feedback mechanisms
 \item Made overly precise predictions
 \end{itemize}

\textbf{Why our prediction is different:}
 \begin{itemize}
 \item We explicitly model the adversarial arms race
 \item We account for economic and structural advantages
 \item We provide ranges, not precise dates
 \item We have empirical evidence of current trajectory
 \item We specify falsification criteria
 \end{itemize}

\textbf{However:} We could still be wrong. Maybe:
 \begin{itemize}
 \item Detection breakthrough we haven't envisioned
 \item Cultural adaptation faster than expected
 \item Regulatory coordination succeeds unexpectedly
 \item Economic incentives shift dramatically
 \end{itemize}

The difference is: we've made our assumptions explicit, provided falsification criteria, and shown why the trajectory is structurally determined.

\subsection{Unknown Unknowns}

\textbf{What could we be missing?}

\textbf{Quantum-based verification methods:} Currently theoretical, no clear path to deployment, but might provide unforgeable signatures based on quantum effects.

\textbf{Emergent social technologies:} New coordination mechanisms we haven't conceived that work without verification.

\textbf{AI capability plateaus:} No historical precedent, but theoretically possible that AI development slows dramatically.

\textbf{Cultural adaptation we haven't envisioned:} Humans are creative. Maybe we develop coordination mechanisms that work despite verification failure.

\textbf{Regulatory breakthroughs:} International coordination on AI development restrictions. Low probability given state competition dynamics.

\textbf{The honest assessment:} We don't know what we don't know. The best we can do is:
 \begin{itemize}
 \item Make assumptions explicit
 \item Provide falsification criteria
 \item Track metrics in real-time
 \item Update as evidence changes
 \item Act on best available evidence
 \end{itemize}

\subsection{Why Uncertainty Doesn't Change Urgency}

\textbf{The asymmetry again:}

Even with significant uncertainty about exact timeline:

\begin{table}[h]
\centering
\begin{tabular}{lll}
\toprule
Timeline Scenario &   Probability &   Action Required \\
\midrule
Threshold in 2 years &   20\% &   Act immediately \\
Threshold in 4 years &   50\% &   Act immediately \\
Threshold in 6 years &   20\% &   Act immediately \\
Threshold in 10+ years &   10\% &   Act immediately \\
\bottomrule
\end{tabular}
\end{table}


\textbf{All scenarios require immediate action} because:
 \begin{itemize}
 \item Examination takes time (can't be rushed)
 \item If you wait for certainty, it's too late
 \item No cost to acting early if timeline is longer
 \item Catastrophic cost to acting late if timeline is shorter
 \end{itemize}

\textbf{Expected value calculation:}

Let $t$ = actual time to threshold, $p(t)$ = probability distribution over $t$.

Expected value of acting now:
$E[V_{now}] = \int_0^{\infty} V(t) \cdot p(t) \, dt$

Expected value of waiting:
$E[V_{wait}] = \int_0^{t_{wait}} 0 \cdot p(t) \, dt + \int_{t_{wait}}^{\infty} V(t - t_{wait}) \cdot p(t) \, dt$

Since $V(t - t_{wait}) < V(t)$ (less time available), and there's probability mass in $[0, t_{wait}]$ that's lost entirely:

$E[V_{now}] > E[V_{wait}]$

\textbf{Translation:} Acting now is superior regardless of uncertainty about exact timeline.

\medskip\hrule\medskip

\subsection{Academic References}

\subsection{Peer-Reviewed Sources (High Confidence)}

\textbf{Human detection performance:}

Diel, A., Lalgi, T., Schröter, I. C., Groh, M., Specker, E., \&   Leder, H. (2024). Human performance in detecting deepfakes: A systematic review and meta-analysis of 56 papers. \emph{Computers in Human Behavior: Artificial Humans}, 2(2), 100085. https://doi.org/10.1016/j.chbah.2024.100085

Somoray, K., Zhao, J., Zheng, W., Phua, J., \&   Sia, S. K. (2025). Human performance in deepfake detection: A systematic review. \emph{Human Behavior and Emerging Technologies}, 2025, 1833228. https://doi.org/10.1155/hbe2/1833228

Groh, M., Epstein, Z., Firestone, C., \&   Picard, R. (2022). Deepfake detection by human crowds, machines, and machine-informed crowds. \emph{Proceedings of the National Academy of Sciences}, 119(1), e2110013119. https://doi.org/10.1073/pnas.2110013119

\textbf{AI detection performance:}

Chandra, N., Murtfeldt, R., Qiu, L., Karmakar, A., Lee, H., Tanumihardja, E., Farhat, K., Caffee, B., Paik, S., Lee, C., Choi, J., Kim, A., \& Etzioni, O. (2025). Deepfake-Eval-2024: A multi-modal in-the-wild benchmark of deepfakes circulated in 2024. arXiv:2503.02857v4. https://arxiv.org/abs/2503.02857

Abbasi, M., Váz, P., Silva, J., \&   Martins, P. (2025). Comprehensive evaluation of deepfake detection models: Accuracy, generalization, and resilience to adversarial attacks. \emph{Applied Sciences}, 15(3), 1225. https://doi.org/10.3390/app15031225

Bhandarkawthekar, V., Navamani, T. M., Sharma, R., \&   Shyamala, K. (2025). Design and development of an efficient RLNet prediction model for deepfake video detection. \emph{Frontiers in Big Data}, 8, 1569147. https://doi.org/10.3389/fdata.2025.1569147

\subsection{Industry Documentation (Medium Confidence)}

\textbf{OpenAI Sora 2:}

OpenAI. (2025, September 30). Sora 2 is here. OpenAI Blog. https://openai.com/index/sora-2/

OpenAI. (2025, September 30). Sora 2 system card. OpenAI Safety. https://openai.com/index/sora-2-system-card/

\subsection{Journalistic Coverage (Lower Confidence for Technical Claims)}

\textbf{Detection challenges:}

Columbia Journalism Review. (2025). What journalists should know about deepfake detection in 2025. https://www.cjr.org/tow\_center/what-journalists-should-know-about-deepfake-detection-technology-in-2025-a-non-technical-guide.php

\subsection{Citation Quality Assessment}

\textbf{High confidence (peer-reviewed, reputable journals):}
- All citations from \emph{Computers in Human Behavior}, \emph{Human Behavior and Emerging Technologies}, \emph{PNAS}, \emph{Applied Sciences}, \emph{Frontiers} journals
 \begin{itemize}
 \item Methodology transparent and reproducible
 \item Independent verification possible
 \end{itemize}

\textbf{Medium confidence (industry documentation, preprints):}
 \begin{itemize}
 \item Deepfake-Eval-2024 (arXiv preprint; methodology sound but not yet peer-reviewed)
 \item OpenAI technical documentation (industry source, no independent verification)
 \end{itemize}

\textbf{Lower confidence (journalistic coverage):}
 \begin{itemize}
 \item Media coverage of capabilities (reporting on claims without independent testing)
 \item Feature-length movie claims (social media posts, no technical roadmap)
 \end{itemize}

\textbf{Critical gaps in available evidence:}
 \begin{itemize}
 \item Limited independent benchmarking of commercial systems
 \item No peer-reviewed papers on some claimed capabilities
 \item Timeline predictions lack formal uncertainty quantification in source material
 \end{itemize}

\medskip\hrule\medskip

\subsection{Conclusion}

\subsection{What the Evidence Establishes}

\textbf{Very high confidence:}
\begin{enumerate}
 \item Current generation capabilities have crossed public detectability threshold for short-form content
 \item Human detection has failed at 55.54\% overall accuracy (barely above chance)
 \item AI detection degrades catastrophically on real-world content (45-50\% performance drop)
 \item Open-source proliferation makes control impossible
 \item Economic incentives strongly favor generation over detection
 \item The gap is widening, not closing
\end{enumerate}

\textbf{High confidence:}
\begin{enumerate}
 \item Expert detection will fail for most content within 3-6 years
 \item Cryptographic countermeasures face insurmountable adoption barriers
 \item Cultural adaptation too slow to prevent crisis period
 \item Verification will become exponentially harder
\end{enumerate}

\textbf{What remains uncertain:}
\begin{enumerate}
 \item Exact timeline to expert detection failure (range: 3-6 years)
 \item Whether detection can achieve breakthrough improvement
 \item Effectiveness of cultural adaptation
 \item Whether regulatory intervention can meaningfully slow development
 \item Feature-length generation timeline (2028-2035 range, high variance)
\end{enumerate}

\subsection{The Direction Is Certain, The Timeline Is Uncertain}

\textbf{But uncertainty about timeline doesn't change the fundamental trajectory.}

Voluntary coordination requires verifiable truth. Within years, routine verification becomes exponentially harder or impossible. The window for building coordination systems based on verifiable reality is closing.

\textbf{You can examine source texts, verify institutional betrayals, and coordinate around observable truth NOW while verification is still possible.} After the threshold, these foundations become unavailable. The examination must happen while truth remains knowable.

\subsection{Decision Framework}

\textbf{Given timeline uncertainty, how should we act?}

\textbf{Conservative estimate:} 6 years to threshold
 \begin{itemize}
 \item Provides some breathing room
 \item Still requires immediate action (examination takes years)
 \item No room for delay
 \end{itemize}

\textbf{Aggressive estimate:} 2-3 years to threshold
 \begin{itemize}
 \item Requires immediate action
 \item No time for delay or preparation
 \item Must begin examination now
 \end{itemize}

\textbf{Rational strategy:} Act on aggressive timeline.

\textbf{Why?} Asymmetry of outcomes:
 \begin{itemize}
 \item If conservative estimate correct and we act aggressively: No harm, extra time is bonus
 \item If aggressive estimate correct and we delay: Catastrophic, miss window entirely
 \end{itemize}

\textbf{Expected value maximization requires acting on short timeline.}

\subsection{This Is Not Speculation}

This is documented technological reality unfolding in real-time:
\begin{itemize}
 \item Human detection: 55.54\% (published meta-analysis)
 \item AI detection degradation: 45-50\% drop (peer-reviewed studies)
 \item Open-source gap: 4.52\% $\to$ 0.69\% in 6 months (documented)
 \item Economic incentives: 1000:1 funding disparity (observable)
\end{itemize}

The evidence is clear. The trajectory is established. The window is closing.

\textbf{You can examine while truth is verifiable, or wait until it's impossible.}

The choice is yours, but the window won't wait for you to decide.

\medskip\hrule\medskip

\subsection{Notation and Terminology Reference}

\begin{table}[h]
\centering
\begin{tabular}{ll}
\toprule
Term &   Definition \\
\midrule
FVD &   Fréchet Video Distance (lower is better; measures video quality) \\
MOS &   Mean Opinion Score (scale of 1-5 for perceived quality) \\
AUC &   Area Under Curve (detection accuracy metric; 1.0 = perfect) \\
Deepfake &   Synthetic media created by AI to impersonate real people/events \\
Detection threshold &   Point where detection accuracy falls below useful level (~60\% for experts, ~25\% for public) \\
Generation &   Creating synthetic media (video, audio, image, text) \\
Detection &   Identifying synthetic media as fake \\
Open-source &   Publicly available code/models anyone can use \\
Commercial &   Proprietary systems available only through companies \\
Real-world performance &   Accuracy on actual deepfakes from social media (vs. academic benchmarks) \\
Academic benchmarks &   Controlled test datasets with known generation techniques \\
\bottomrule
\end{tabular}
\end{table}


\medskip\hrule\medskip

\subsection{Final Assessment}

This appendix establishes:
- \textbf{Current state:} Public detection has failed; expert detection struggling
- \textbf{Trajectory:} Gap widening as generation improves faster than detection
- \textbf{Timeline:} 3-6 years (high confidence) until expert detection fails
- \textbf{Countermeasures:} Unlikely to prevent threshold crossing
- \textbf{Implications:} Window for verification-based coordination is closing
- \textbf{Action required:} Examine NOW while truth remains verifiable

\textbf{The evidence is conclusive. The stakes are absolute. The window is closing.}

